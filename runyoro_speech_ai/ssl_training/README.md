# Self-Supervised Learning (SSL) Model Training

This section details the pipeline for pre-training a Self-Supervised Learning (SSL) model for the Runyoro language. The goal is to adapt a large, existing multilingual speech model to better understand the acoustic properties of Runyoro.

## Chosen SSL Model and Base Checkpoint

-   **Model Architecture:** Wav2Vec 2.0 (XLSR variant)
    -   **Rationale:** XLSR (Cross-lingual Speech Representations) models are pre-trained on diverse multilingual speech data, making them highly effective for transfer learning to low-resource languages. They learn robust speech representations that can be fine-tuned for specific tasks or further pre-trained on target language data.
-   **Base Checkpoint:** `facebook/wav2vec2-xls-r-300m`
    -   **Source:** Hugging Face Model Hub
    -   **Parameters:** 300 Million
    -   **Rationale for Choice:** This model offers a strong balance between performance and computational requirements. It is suitable for continued pre-training on a high-end local machine like a MacBook Pro M4 with MPS support. Larger models (e.g., XLSR-1B, XLSR-2B) exist but would likely be too demanding for the specified hardware constraints during the pre-training phase.
    -   **Hugging Face Link:** [facebook/wav2vec2-xls-r-300m](https://huggingface.co/facebook/wav2vec2-xls-r-300m)

## Training Approach

The approach will be **continued pre-training** (also known as domain adaptation). We will take the `facebook/wav2vec2-xls-r-300m` checkpoint and continue its pre-training regimen, but using only our processed Runyoro audio corpus. This will help the model's learned representations become more specialized for Runyoro speech.

## Environment and Dependencies

The following Python libraries are essential for the SSL training phase. If a `requirements.txt` file is established for the project, these should be included:

-   `torch` (ensure version with MPS support for Apple Silicon, e.g., >=1.12 or nightly for older versions)
-   `torchaudio`
-   `transformers` (a recent version, e.g., >=4.20.0)
-   `datasets`
-   `accelerate` (for efficient training, distributed training, and MPS integration)
-   `scipy` (often a dependency for audio processing and signal handling in datasets)
-   `wandb` (optional, for logging metrics - highly recommended)
-   `tensorboard` (alternative for logging metrics)

**System Dependencies:**
-   `ffmpeg` (if not already ensured, for robust audio file loading by `datasets` or `torchaudio` backends)

## Data Preparation

Before starting the SSL pre-training, the raw audio data (from the manifest file) needs to be processed into a format suitable for the model. This is handled by the `prepare_ssl_data.py` script.

**Steps:**

1.  **Ensure Manifest File Exists:** You should have a `audio_manifest.jsonl` file generated by the data ingestion pipeline (e.g., at `runyoro_speech_ai/data/manifest/audio_manifest.jsonl`).
2.  **Run `prepare_ssl_data.py`:**
    ```bash
    python ./ssl_training/prepare_ssl_data.py \
        --manifest_path ./data/manifest/audio_manifest.jsonl \
        --output_dir ./data/processed/ssl_dataset/ \
        --model_name_or_path facebook/wav2vec2-xls-r-300m \
        --max_duration_sec 15 \
        --min_duration_sec 2 \
        --num_workers 4 # Adjust based on your CPU cores
    ```
3.  **Output:** This script will create a Hugging Face `Dataset` in the specified `--output_dir` (e.g., `./data/processed/ssl_dataset/`). This directory will contain files like `dataset.arrow`, `dataset_info.json`, etc.

**Key `prepare_ssl_data.py` Arguments:**
*   `--manifest_path`: Path to your JSONL audio manifest.
*   `--output_dir`: Where the processed Hugging Face dataset will be saved.
*   `--model_name_or_path`: Base model ID (used for its feature extractor).
*   `--max_duration_sec`: Maximum duration of audio clips to include (in seconds).
*   `--min_duration_sec`: Minimum duration of audio clips to include (in seconds).
*   `--num_workers`: Number of CPU cores for parallel processing.

## SSL Model Training

Once the dataset is prepared, you can start the continued pre-training using the `train_ssl.py` script.

**Running `train_ssl.py`:**

```bash
python ./ssl_training/train_ssl.py \
    --processed_dataset_path ./data/processed/ssl_dataset/ \
    --model_name_or_path facebook/wav2vec2-xls-r-300m \
    --output_dir ./models/ssl/runyoro-wav2vec2-xls-r-300m-continued-training/ \
    --num_train_epochs 10 # Adjust as needed
    --per_device_train_batch_size 4 # Adjust based on GPU/MPS memory
    --gradient_accumulation_steps 8 # Effective batch size = batch_size * grad_accum
    --learning_rate 5e-5
    --warmup_steps 500
    --weight_decay 0.01
    --logging_steps 10
    --save_steps 500
    --save_total_limit 3
    --fp16 \ # Use if your GPU/MPS supports mixed precision
    --seed 42 \
    --dataloader_num_workers 4 # Adjust based on CPU cores
    --mask_time_prob 0.05 \
    --mask_time_length 10
```

**Key `train_ssl.py` Arguments:**
*   `--processed_dataset_path`: Path to the dataset created by `prepare_ssl_data.py`.
*   `--model_name_or_path`: The base pre-trained model to start from (e.g., `facebook/wav2vec2-xls-r-300m`).
*   `--output_dir`: Where the fine-tuned model checkpoints and logs will be saved.
*   `--num_train_epochs`: Number of training epochs.
*   `--per_device_train_batch_size`: Batch size per GPU/MPS device.
*   `--gradient_accumulation_steps`: Accumulate gradients over multiple steps to simulate a larger batch size.
*   `--learning_rate`: Peak learning rate.
*   `--warmup_steps`: Number of steps for learning rate warmup.
*   `--logging_steps`: How often to log training metrics.
*   `--save_steps`: How often to save a model checkpoint.
*   `--fp16`: Enable mixed-precision training (reduces memory and can speed up training on compatible hardware).
*   Masking parameters (`--mask_time_prob`, etc.): Control the masking strategy for Wav2Vec2 pre-training.

**Test Run:**
A script for a very short test run is available at `scripts/test_run_ssl.sh`. This can be used to verify that the training pipeline starts correctly before launching a full training job.
```bash
bash ./scripts/test_run_ssl.sh
```
Note: For this test script to accurately check data loading, you must first run `prepare_ssl_data.py` on a small sample of your data and point `--processed_dataset_path` in `test_run_ssl.sh` (or its internal variable) to this sample processed dataset. The current `test_run_ssl.sh` creates a placeholder that might only pass initial script startup checks.

## Expected Outputs & Monitoring

-   **Model Checkpoints:** Saved in subdirectories within the `--output_dir` (e.g., `checkpoint-500`, `checkpoint-1000`).
-   **Logs:** Training progress (loss, learning rate, etc.) will be printed to the console. If `tensorboard` or `wandb` is configured (via `TrainingArguments`), logs will also be sent there.
-   **Final Model:** The final trained model will be saved in the root of the `--output_dir` after training completes.

## Future Considerations
If more substantial computational resources (e.g., cloud GPUs) become available, experimenting with larger base models like `facebook/wav2vec2-xls-r-1b` could be considered for potentially higher performance.
